import { Kind, parse, GraphQLSchema, Source } from 'graphql';
import { debugLog, asArray, resolveBuiltinModule, isDocumentString, parseGraphQLSDL, printSchemaWithDirectives, fixSchemaAst } from '@graphql-toolkit/common';
import isGlob from 'is-glob';
import { uniqBy, keyBy, reverse, includes, flatten, isEqual, groupBy } from 'lodash';
import { printWithComments, mergeResolvers, mergeSchemasAsync } from '@graphql-toolkit/schema-merging';
import { loadFilesAsync } from '@graphql-toolkit/file-loading';

const filterKind = (content, filterKinds) => {
    if (content && content.definitions && content.definitions.length && filterKinds && filterKinds.length > 0) {
        const invalidDefinitions = [];
        const validDefinitions = [];
        for (const definitionNode of content.definitions) {
            if (filterKinds.includes(definitionNode.kind)) {
                invalidDefinitions.push(definitionNode);
            }
            else {
                validDefinitions.push(definitionNode);
            }
        }
        if (invalidDefinitions.length > 0) {
            invalidDefinitions.forEach(d => {
                debugLog(`Filtered document of kind ${d.kind} due to filter policy (${filterKinds.join(', ')})`);
            });
        }
        return {
            kind: Kind.DOCUMENT,
            definitions: validDefinitions,
        };
    }
    return content;
};

const builtinTypes = ['String', 'Float', 'Int', 'Boolean', 'ID', 'Upload'];
const builtinDirectives = ['deprecated', 'skip', 'include', 'cacheControl', 'key', 'external', 'requires', 'provides'];
/**
 * Post processing of all imported type definitions. Loops over each of the
 * imported type definitions, and processes it using collectNewTypeDefinitions.
 *
 * @param allDefinitions All definitions from all schemas
 * @param definitionPool Current definitions (from first schema)
 * @param newTypeDefinitions All imported definitions
 * @returns Final collection of type definitions for the resulting schema
 */
function completeDefinitionPool(allDefinitions, definitionPool, newTypeDefinitions) {
    const visitedDefinitions = {};
    while (newTypeDefinitions.length > 0) {
        const schemaMap = keyBy(reverse(allDefinitions), d => ('name' in d ? d.name.value : 'schema'));
        const newDefinition = newTypeDefinitions.shift();
        if (visitedDefinitions['name' in newDefinition ? newDefinition.name.value : 'schema']) {
            continue;
        }
        const collectedTypedDefinitions = collectNewTypeDefinitions(allDefinitions, definitionPool, newDefinition, schemaMap);
        newTypeDefinitions.push(...collectedTypedDefinitions);
        definitionPool.push(...collectedTypedDefinitions);
        visitedDefinitions['name' in newDefinition ? newDefinition.name.value : 'schema'] = true;
    }
    return uniqBy(definitionPool, 'name.value');
}
/**
 * Processes a single type definition, and performs a number of checks:
 * - Add missing interface implementations
 * - Add missing referenced types
 * - Remove unused type definitions
 *
 * @param allDefinitions All definitions from all schemas
 * (only used to find missing interface implementations)
 * @param definitionPool Resulting definitions
 * @param newDefinition All imported definitions
 * @param schemaMap Map of all definitions for easy lookup
 * @returns All relevant type definitions to add to the final schema
 */
function collectNewTypeDefinitions(allDefinitions, definitionPool, newDefinition, schemaMap) {
    let newTypeDefinitions = [];
    if (newDefinition.kind !== 'DirectiveDefinition') {
        newDefinition.directives.forEach(collectDirective);
    }
    if (newDefinition.kind === 'InputObjectTypeDefinition') {
        newDefinition.fields.forEach(collectNode);
    }
    if (newDefinition.kind === 'InterfaceTypeDefinition') {
        const interfaceName = newDefinition.name.value;
        newDefinition.fields.forEach(collectNode);
        const interfaceImplementations = allDefinitions.filter(d => d.kind === 'ObjectTypeDefinition' && d.interfaces.some(i => i.name.value === interfaceName));
        newTypeDefinitions.push(...interfaceImplementations);
    }
    if (newDefinition.kind === 'UnionTypeDefinition') {
        newDefinition.types.forEach(type => {
            if (!definitionPool.some(d => 'name' in d && d.name.value === type.name.value)) {
                const typeName = type.name.value;
                const typeMatch = schemaMap[typeName];
                if (!typeMatch) {
                    throw new Error(`Couldn't find type ${typeName} in any of the schemas.`);
                }
                newTypeDefinitions.push(schemaMap[type.name.value]);
            }
        });
    }
    if (newDefinition.kind === 'ObjectTypeDefinition') {
        // collect missing interfaces
        newDefinition.interfaces.forEach(int => {
            if (!definitionPool.some(d => 'name' in d && d.name.value === int.name.value)) {
                const interfaceName = int.name.value;
                const interfaceMatch = schemaMap[interfaceName];
                if (!interfaceMatch) {
                    throw new Error(`Couldn't find interface ${interfaceName} in any of the schemas.`);
                }
                newTypeDefinitions.push(schemaMap[int.name.value]);
            }
        });
        // iterate over all fields
        newDefinition.fields.forEach(field => {
            collectNode(field);
            // collect missing argument input types
            field.arguments.forEach(collectNode);
        });
    }
    if (newDefinition.kind === 'SchemaDefinition') {
        newDefinition.operationTypes.forEach(operationType => {
            if (!definitionPool.some(d => 'name' in d && d.name.value === operationType.type.name.value)) {
                const typeName = operationType.type.name.value;
                const typeMatch = schemaMap[typeName];
                if (!typeMatch) {
                    throw new Error(`Couldn't find type ${typeName} in any of the schemas.`);
                }
                newTypeDefinitions.push(schemaMap[operationType.type.name.value]);
            }
        });
    }
    if (newDefinition.kind === Kind.OPERATION_DEFINITION || newDefinition.kind === Kind.FRAGMENT_DEFINITION) {
        if (newDefinition.selectionSet) {
            for (const selection of newDefinition.selectionSet.selections) {
                collectFragments(selection);
            }
        }
    }
    return newTypeDefinitions;
    function collectFragments(node) {
        if (node.kind === Kind.FRAGMENT_SPREAD) {
            const fragmentName = node.name.value;
            if (!definitionPool.some(d => 'name' in d && d.name.value === fragmentName)) {
                const fragmentMatch = schemaMap[fragmentName];
                if (!fragmentMatch) {
                    throw new Error(`Fragment ${fragmentName}: Couldn't find fragment ${fragmentName} in any of the documents.`);
                }
                newTypeDefinitions.push(fragmentMatch);
            }
        }
        else if (node.selectionSet) {
            for (const selection of node.selectionSet.selections) {
                for (const directive of node.directives) {
                    collectDirective(directive);
                }
                collectFragments(selection);
            }
        }
    }
    function collectNode(node) {
        const nodeType = getNamedType(node.type);
        const nodeTypeName = nodeType.name.value;
        // collect missing argument input types
        if (!definitionPool.some(d => 'name' in d && d.name.value === nodeTypeName) && !includes(builtinTypes, nodeTypeName)) {
            const argTypeMatch = schemaMap[nodeTypeName];
            if (!argTypeMatch) {
                throw new Error(`Field ${node.name.value}: Couldn't find type ${nodeTypeName} in any of the schemas.`);
            }
            newTypeDefinitions.push(argTypeMatch);
        }
        node.directives.forEach(collectDirective);
    }
    function collectDirective(directive) {
        const directiveName = directive.name.value;
        if (!definitionPool.some(d => 'name' in d && d.name.value === directiveName) && !includes(builtinDirectives, directiveName)) {
            const directive = schemaMap[directiveName];
            if (!directive) {
                throw new Error(`Directive ${directiveName}: Couldn't find type ${directiveName} in any of the schemas.`);
            }
            directive.arguments.forEach(collectNode);
            newTypeDefinitions.push(directive);
        }
    }
}
/**
 * Nested visitor for a type node to get to the final NamedType
 *
 * @param {TypeNode} type Type node to get NamedTypeNode for
 * @returns {NamedTypeNode} The found NamedTypeNode
 */
function getNamedType(type) {
    if (type.kind === 'NamedType') {
        return type;
    }
    else {
        return getNamedType(type.type);
    }
}

const rootFields = ['Query', 'Mutation', 'Subscription'];
const gqlExt = /\.g(raph)?ql(s)?$/;
function isGraphQLFile(f) {
    return gqlExt.test(f);
}
const IMPORT_FROM_REGEX = /^import\s+(\*|(.*))\s+from\s+('|")(.*)('|");?$/;
const IMPORT_DEFAULT_REGEX = /^import\s+('|")(.*)('|");?$/;
/**
 * Parse a single import line and extract imported types and schema filename
 *
 * @param importLine Import line
 * @returns Processed import line
 */
function parseImportLine(importLine) {
    if (IMPORT_FROM_REGEX.test(importLine)) {
        // Apply regex to import line
        const matches = importLine.match(IMPORT_FROM_REGEX);
        if (matches && matches.length === 6 && matches[4]) {
            // Extract matches into named variables
            const [, wildcard, importsString, , from] = matches;
            // Extract imported types
            const imports = wildcard === '*' ? ['*'] : importsString.split(',').map(d => d.trim());
            // Return information about the import line
            return { imports, from };
        }
    }
    else if (IMPORT_DEFAULT_REGEX.test(importLine)) {
        const [, , from] = importLine.match(IMPORT_DEFAULT_REGEX);
        return { imports: ['*'], from };
    }
    throw new Error(`
    Import statement is not valid: ${importLine}
    If you want to have comments starting with '# import', please use ''' instead!
    You can only have 'import' statements in the following pattern;
    # import [Type].[Field] from [File]
  `);
}
/**
 * Parse a schema and analyze all import lines
 *
 * @param sdl Schema to parse
 * @returns Array with collection of imports per import line (file)
 */
function parseSDL(sdl) {
    return sdl
        .split('\n')
        .map(l => l.trim())
        .filter(l => l.startsWith('# import ') || l.startsWith('#import '))
        .map(l => l.replace('#', '').trim())
        .map(parseImportLine);
}
/**
 * Main entry point. Recursively process all import statement in a schema
 *
 * @param filePath File path to the initial schema file
 * @returns Single bundled schema with all imported types
 */
async function processImportSyntax(documentSource, options) {
    let document = documentSource.document;
    // Recursively process the imports, starting by importing all types from the initial schema
    await collectDefinitions(['*'], documentSource, options);
    // Post processing of the final schema (missing types, unused types, etc.)
    // Query, Mutation and Subscription should be merged
    // And should always be in the first set, to make sure they
    // are not filtered out.
    const firstTypes = flatten(options.typeDefinitions);
    const secondFirstTypes = options.typeDefinitions[0];
    const otherFirstTypes = flatten(options.typeDefinitions.slice(1));
    const firstSet = firstTypes.concat(secondFirstTypes, otherFirstTypes);
    const processedTypeNames = [];
    const mergedFirstTypes = [];
    for (const type of firstSet) {
        if ('name' in type) {
            if (!processedTypeNames.includes(type.name.value)) {
                processedTypeNames.push(type.name.value);
                mergedFirstTypes.push(type);
            }
            else {
                const existingType = mergedFirstTypes.find(t => t.name.value === type.name.value);
                if ('fields' in existingType) {
                    existingType.fields = uniqBy(existingType.fields.concat(type.fields), 'name.value');
                    if (options.sort) {
                        existingType.fields = existingType.fields.sort((a, b) => a.name.value.localeCompare(b.name.value));
                    }
                }
            }
        }
    }
    document.definitions = completeDefinitionPool(flatten(options.allDefinitions), firstSet, flatten(options.typeDefinitions));
}
/**
 * Parses a schema into a graphql DocumentNode.
 * If the schema is empty a DocumentNode with empty definitions will be created.
 *
 * @param sdl Schema to parse
 * @returns A graphql DocumentNode with definitions of the parsed sdl.
 */
function getDocumentFromSDL(sdl) {
    if (isEmptySDL(sdl)) {
        return {
            kind: Kind.DOCUMENT,
            definitions: [],
        };
    }
    else {
        return parse(sdl, { noLocation: true });
    }
}
/**
 * Check if a schema contains any type definitions at all.
 *
 * @param sdl Schema to parse
 * @returns True if SDL only contains comments and/or whitespaces
 */
function isEmptySDL(sdl) {
    return (sdl
        .split('\n')
        .map(l => l.trim())
        .filter(l => !(l.length === 0 || l.startsWith('#'))).length === 0);
}
/**
 * Resolve the path of an import.
 * First it will try to find a file relative from the file the import is in, if that fails it will try to resolve it as a module so imports from packages work correctly.
 *
 * @param filePath Path the import was made from
 * @param importFrom Path given for the import
 * @returns Full resolved path to a file
 */
async function resolveModuleFilePath(filePath, importFrom, options) {
    const { fs, path } = options;
    if (fs && path) {
        const fullPath = path.resolve(options.cwd, filePath);
        const dirName = path.dirname(fullPath);
        if (isGraphQLFile(fullPath) && isGraphQLFile(importFrom)) {
            try {
                return await new Promise((resolve, reject) => fs.realpath(path.join(dirName, importFrom), (err, data) => (err ? reject(err) : resolve(data))));
            }
            catch (e) {
                if (e.code === 'ENOENT') {
                    const resolveFrom = await import('resolve-from').then(m => m.default);
                    return resolveFrom(dirName, importFrom);
                }
            }
        }
    }
    return importFrom;
}
/**
 * Recursively process all schema files. Keeps track of both the filtered
 * type definitions, and all type definitions, because they might be needed
 * in post-processing (to add missing types)
 *
 * @param imports Types specified in the import statement
 * @param sdl Current schema
 * @param filePath File location for current schema
 * @param Tracking of processed schemas (for circular dependencies)
 * @param Tracking of imported type definitions per schema
 * @param Tracking of all type definitions per schema
 * @returns Both the collection of all type definitions, and the collection of imported type definitions
 */
async function collectDefinitions(imports, documentSource, options) {
    // Get TypeDefinitionNodes from current schema
    const document = documentSource.document;
    // Add all definitions to running total
    options.allDefinitions.push(document.definitions);
    // Filter TypeDefinitionNodes by type and defined imports
    const currentTypeDefinitions = filterImportedDefinitions(imports, document.definitions, options.allDefinitions, options.sort);
    // Add typedefinitions to running total
    options.typeDefinitions.push(currentTypeDefinitions);
    // Read imports from current file
    const rawModules = parseSDL(documentSource.rawSDL);
    // Process each file (recursively)
    await Promise.all(rawModules.map(async (m) => {
        // If it was not yet processed (in case of circular dependencies)
        const moduleFilePath = await resolveModuleFilePath(documentSource.location, m.from, options);
        const processedFile = options.processedFiles.get(moduleFilePath);
        if (!processedFile || !processedFile.find(rModule => isEqual(rModule, m))) {
            // Mark this specific import line as processed for this file (for cicular dependency cases)
            options.processedFiles.set(moduleFilePath, processedFile ? processedFile.concat(m) : [m]);
            const result = await loadSingleFile(moduleFilePath, options);
            await collectDefinitions(m.imports, result, options);
        }
    }));
}
/**
 * Filter the types loaded from a schema, first by relevant types,
 * then by the types specified in the import statement.
 *
 * @param imports Types specified in the import statement
 * @param typeDefinitions All definitions from a schema
 * @returns Filtered collection of type definitions
 */
function filterImportedDefinitions(imports, typeDefinitions, allDefinitions, sort) {
    // This should do something smart with fields
    const filteredDefinitions = typeDefinitions;
    if (imports.includes('*')) {
        if (imports.length === 1 && imports[0] === '*' && allDefinitions.length > 1) {
            const previousTypeDefinitions = keyBy(flatten(allDefinitions.slice(0, allDefinitions.length - 1)).filter(def => 'name' in def && !rootFields.includes(def.name.value)), def => 'name' in def && def.name.value);
            return typeDefinitions.filter(typeDef => typeDef.kind === 'ObjectTypeDefinition' && previousTypeDefinitions[typeDef.name.value]);
        }
        return filteredDefinitions;
    }
    else {
        const importedTypes = imports.map(i => i.split('.')[0]);
        const result = filteredDefinitions.filter(d => 'name' in d && importedTypes.includes(d.name.value));
        const fieldImports = imports.filter(i => i.split('.').length > 1);
        const groupedFieldImports = groupBy(fieldImports, x => x.split('.')[0]);
        for (const rootType in groupedFieldImports) {
            const fields = groupedFieldImports[rootType].map(x => x.split('.')[1]);
            const objectTypeDefinition = filteredDefinitions.find(def => 'name' in def && def.name.value === rootType);
            if (objectTypeDefinition && 'fields' in objectTypeDefinition && !fields.includes('*')) {
                objectTypeDefinition.fields = objectTypeDefinition.fields.filter((f) => fields.includes(f.name.value) || fields.includes('*'));
                if (sort) {
                    objectTypeDefinition.fields.sort((a, b) => a.name.value.localeCompare(b.name.value));
                }
            }
        }
        return result;
    }
}

function normalizePointers(unnormalizedPointerOrPointers) {
    return asArray(unnormalizedPointerOrPointers).reduce((normalizedPointers, unnormalizedPointer) => {
        if (typeof unnormalizedPointer === 'string') {
            normalizedPointers[unnormalizedPointer] = {};
        }
        else if (typeof unnormalizedPointer === 'object') {
            Object.assign(normalizedPointers, unnormalizedPointer);
        }
        else {
            throw new Error(`Invalid pointer ${unnormalizedPointer}`);
        }
        return normalizedPointers;
    }, {});
}
async function getCustomLoaderByPath(path, cwd) {
    try {
        const { default: importFrom } = await import('import-from');
        const requiredModule = importFrom(cwd, path);
        if (requiredModule) {
            if (requiredModule.default && typeof requiredModule.default === 'function') {
                return requiredModule.default;
            }
            else if (typeof requiredModule === 'function') {
                return requiredModule;
            }
        }
        return null;
    }
    catch (e) {
        return null;
    }
}
// Convert to 32bit integer
function stringToHash(str) {
    let hash = 0;
    if (str.length == 0)
        return hash;
    let char;
    for (let i = 0; i < str.length; i++) {
        char = str.charCodeAt(i);
        hash = (hash << 5) - hash + char;
        hash = hash & hash;
    }
    return hash;
}
async function loadTypedefs(pointerOrPointers, options) {
    const normalizedPointerOptionsMap = normalizePointers(pointerOrPointers);
    const loadPromises$ = [];
    const found = [];
    const foundGlobs = [];
    const globOptions = {};
    options.cache = options.cache || {};
    options.cwd = options.cwd || process.cwd();
    options.sort = 'sort' in options ? options.sort : true;
    options.processedFiles = options.processedFiles || new Map();
    options.allDefinitions = options.allDefinitions || [];
    options.typeDefinitions = options.typeDefinitions || [];
    options.fs = await resolveBuiltinModule('fs', options.fs);
    options.path = await resolveBuiltinModule('path', options.path);
    options.os = await resolveBuiltinModule('os', options.os);
    const unixify = await import('unixify').then(m => m.default || m);
    for (const pointer in normalizedPointerOptionsMap) {
        const pointerOptions = normalizedPointerOptionsMap[pointer];
        if (isDocumentString(pointer)) {
            loadPromises$.push(Promise.resolve().then(async () => {
                const result = parseGraphQLSDL(`${stringToHash(pointer)}.graphql`, pointer, options);
                found.push(result);
                options.cache[pointer] = result;
            }));
        }
        else if (isGlob(unixify(pointer))) {
            foundGlobs.push(unixify(pointer));
            Object.assign(globOptions, pointerOptions);
        }
        else if (pointerOptions.loader) {
            loadPromises$.push(Promise.resolve().then(async () => {
                let loader;
                if (typeof pointerOptions.loader === 'string') {
                    loader = await getCustomLoaderByPath(pointerOptions.loader, options.cwd);
                }
                else if (typeof pointerOptions.loader === 'function') {
                    loader = pointerOptions.loader;
                }
                if (typeof loader !== 'function') {
                    throw new Error(`Failed to load custom loader: ${pointerOptions.loader}`);
                }
                const customLoaderResult = await loader(pointer, Object.assign(Object.assign({}, options), pointerOptions), normalizedPointerOptionsMap);
                if (customLoaderResult && customLoaderResult instanceof GraphQLSchema) {
                    found.push({
                        location: pointer,
                        schema: customLoaderResult,
                    });
                }
                else if (customLoaderResult && customLoaderResult.kind && customLoaderResult.kind === Kind.DOCUMENT) {
                    const result = {
                        document: customLoaderResult,
                        location: pointer,
                    };
                    options.cache[pointer] = result;
                    found.push(result);
                }
                else if (customLoaderResult && customLoaderResult.document) {
                    const result = Object.assign({ location: pointer }, customLoaderResult);
                    options.cache[pointer] = result;
                    found.push(result);
                }
            }));
        }
        else {
            loadPromises$.push(Promise.resolve().then(async () => {
                const combinedOptions = Object.assign(Object.assign({}, options), pointerOptions);
                const loaderResult = await loadSingleFile(pointer, combinedOptions);
                options.cache[pointer] = loaderResult;
                found.push(loaderResult);
            }));
        }
    }
    if (foundGlobs.length > 0) {
        if (options.ignore) {
            const ignoreList = asArray(options.ignore)
                .map(g => `!(${g})`)
                .map(unixify);
            if (ignoreList.length > 0) {
                foundGlobs.push(...ignoreList);
            }
        }
        loadPromises$.push(Promise.resolve().then(async () => {
            const { default: globby } = await import('globby');
            const paths = await globby(foundGlobs, Object.assign(Object.assign({ absolute: true }, options), { ignore: [] }));
            await Promise.all(paths.map(async (path) => {
                if (globOptions.loader) {
                    let loader;
                    if (typeof globOptions.loader === 'string') {
                        loader = await getCustomLoaderByPath(globOptions.loader, options.cwd);
                    }
                    else if (typeof globOptions.loader === 'function') {
                        loader = globOptions.loader;
                    }
                    if (typeof loader !== 'function') {
                        throw new Error(`Failed to load custom loader: ${globOptions.loader}`);
                    }
                    const customLoaderResult = await loader(path, Object.assign(Object.assign({}, options), globOptions), normalizedPointerOptionsMap);
                    if (customLoaderResult instanceof GraphQLSchema) {
                        const result = {
                            schema: customLoaderResult,
                            document: parse(printSchemaWithDirectives(customLoaderResult)),
                            location: path,
                        };
                        options.cache[path] = result;
                        found.push(result);
                    }
                    else if (customLoaderResult && customLoaderResult.kind && customLoaderResult.kind === Kind.DOCUMENT) {
                        const result = {
                            document: customLoaderResult,
                            location: path,
                        };
                        options.cache[path] = result;
                        found.push(result);
                    }
                    else if (customLoaderResult && customLoaderResult.document) {
                        const result = Object.assign({ location: path }, customLoaderResult);
                        options.cache[path] = result;
                        found.push(result);
                    }
                }
                else {
                    const loaderResult = await loadSingleFile(path, Object.assign(Object.assign({}, options), globOptions));
                    options.cache[path] = loaderResult;
                    found.push(loaderResult);
                }
            }));
        }));
    }
    await Promise.all(loadPromises$);
    const foundValid = [];
    await Promise.all(found.map(async (partialSource) => {
        if (partialSource) {
            const resultSource = Object.assign({}, partialSource);
            if (resultSource.schema) {
                resultSource.schema = fixSchemaAst(resultSource.schema, options);
                resultSource.rawSDL = printSchemaWithDirectives(resultSource.schema);
            }
            if (resultSource.rawSDL) {
                if (isEmptySDL(resultSource.rawSDL)) {
                    resultSource.document = {
                        kind: Kind.DOCUMENT,
                        definitions: [],
                    };
                }
                else {
                    resultSource.document = parse(new Source(resultSource.rawSDL, resultSource.location), options);
                }
            }
            if (resultSource.document) {
                if (options.filterKinds) {
                    resultSource.document = filterKind(resultSource.document, options.filterKinds);
                }
                if (!resultSource.rawSDL) {
                    resultSource.rawSDL = printWithComments(resultSource.document);
                }
                if (options.forceGraphQLImport || (!options.skipGraphQLImport && /^\#.*import /i.test(resultSource.rawSDL.trimLeft()))) {
                    await processImportSyntax(resultSource, options);
                }
                if (resultSource.document.definitions && resultSource.document.definitions.length > 0) {
                    foundValid.push(resultSource);
                }
            }
        }
    }));
    const pointerList = Object.keys(normalizedPointerOptionsMap);
    if (pointerList.length > 0 && foundValid.length === 0) {
        throw new Error(`Unable to find any GraphQL type definitions for the following pointers: ${pointerList.join(', ')}`);
    }
    return options.sort ? foundValid.sort((left, right) => left.location.localeCompare(right.location)) : foundValid;
}
async function loadSingleFile(pointer, options) {
    if (pointer in options.cache) {
        return options.cache[pointer];
    }
    let error;
    let found;
    await Promise.all(options.loaders.map(async (loader) => {
        try {
            const canLoad = await loader.canLoad(pointer, options);
            if (canLoad) {
                found = await loader.load(pointer, options);
            }
        }
        catch (e) {
            error = e;
        }
    }));
    if (!found && error) {
        debugLog(`Failed to find any GraphQL type definitions in: ${pointer} - ${error.message}`);
        throw error;
    }
    return found;
}

const OPERATION_KINDS = [Kind.OPERATION_DEFINITION, Kind.FRAGMENT_DEFINITION];
const NON_OPERATION_KINDS = Object.keys(Kind)
    .reduce((prev, v) => [...prev, Kind[v]], [])
    .filter(v => !OPERATION_KINDS.includes(v));
function loadDocuments(documentDef, options) {
    return loadTypedefs(documentDef, Object.assign({ noRequire: true, filterKinds: NON_OPERATION_KINDS }, options));
}

async function loadSchema(schemaPointers, options) {
    const sources = await loadTypedefs(schemaPointers, Object.assign({ filterKinds: OPERATION_KINDS }, options));
    const schemas = [];
    const typeDefs = [];
    await Promise.all(sources.map(async (source) => {
        if (source.schema) {
            schemas.push(source.schema);
        }
        else {
            typeDefs.push(source.document);
        }
    }));
    let resolvers = {};
    if (options.resolvers) {
        if (typeof options.resolvers === 'string') {
            resolvers = await loadFilesAsync(options.resolvers);
        }
        else if (options.resolvers instanceof Array) {
            resolvers = mergeResolvers(await Promise.all(options.resolvers.map(async (r) => (typeof options.resolvers === 'string' ? loadFilesAsync(r) : r))));
        }
    }
    const mergeSchemasOptions = Object.assign({ schemas,
        typeDefs,
        resolvers }, options);
    return mergeSchemasAsync(mergeSchemasOptions);
}

export { NON_OPERATION_KINDS, OPERATION_KINDS, collectDefinitions, filterKind, getDocumentFromSDL, isEmptySDL, loadDocuments, loadSchema, loadSingleFile, loadTypedefs, normalizePointers, parseImportLine, parseSDL, processImportSyntax, resolveModuleFilePath };
